#![allow(clippy::all)]
//! Advanced Usage Pattern Examples
//!
//! This example demonstrates EVERY advanced usage pattern for enhanced features:
//! - Custom validation criteria for domain-specific requirements
//! - Template composition and inheritance patterns
//! - Advanced update chain coordination
//! - Performance optimization techniques
//! - Memory-efficient processing for large datasets
//! - Multi-threaded and concurrent processing scenarios

#![ cfg( feature = "enabled" ) ]
#![ cfg( feature = "markdown_reports" ) ]
#![ allow( clippy::uninlined_format_args ) ]
#![ allow( clippy::format_push_string ) ]
#![ allow( clippy::cast_lossless ) ]
#![ allow( clippy::std_instead_of_core ) ]
#![ allow( clippy::cast_sign_loss ) ]
#![ allow( clippy::too_many_lines ) ]
#![ allow( clippy::for_kv_map ) ]
#![ allow( clippy::cast_possible_truncation ) ]
#![ allow( clippy::cast_possible_wrap ) ]
#![ allow( clippy::single_char_pattern ) ]
#![ allow( clippy::unnecessary_cast ) ]

use benchkit::prelude::*;
use std::collections::HashMap;
use std::time::Duration;

/// Create large-scale benchmark results for advanced processing
fn create_large_scale_results() -> HashMap< String, BenchmarkResult >
{
  let mut results = HashMap::new();
  
  // Simulate results from different algorithm categories
  let categories = vec![
    ( "sorting", vec![ "quicksort", "mergesort", "heapsort", "radixsort", "timsort" ] ),
    ( "searching", vec![ "binary_search", "linear_search", "hash_lookup", "tree_search", "bloom_filter" ] ),
    ( "compression", vec![ "gzip", "lz4", "zstd", "brotli", "snappy" ] ),
    ( "encryption", vec![ "aes256", "chacha20", "blake3", "sha256", "md5" ] ),
  ];
  
  for ( category, algorithms ) in categories
  {
    for ( i, algorithm ) in algorithms.iter().enumerate()
    {
      // Generate realistic performance data with some variation
      let base_time = match category
      {
        "sorting" => 100 + i * 50,
        "searching" => 20 + i * 10,
        "compression" => 500 + i * 100,
        "encryption" => 200 + i * 75,
        _ => 100,
      };
      
      let times : Vec< Duration > = ( 0..20 )
        .map( | j | 
        {
          let variance = ( j % 5 ) as i32 - 2;  // ¬±2 microseconds
          Duration::from_micros( ( base_time as i32 + variance ) as u64 )
        })
        .collect();
      
      let full_name = format!( "{}_{}", category, algorithm );
      results.insert( full_name.clone(), BenchmarkResult::new( &full_name, times ) );
    }
  }
  
  results
}

/// Advanced Pattern 1: Custom Domain-Specific Validation
fn pattern_domain_specific_validation()
{
  println!( "=== Pattern 1: Domain-Specific Validation ===" );
  
  let results = create_large_scale_results();
  
  // Create different validators for different domains
  
  // Real-time systems validator (very strict)
  let realtime_validator = BenchmarkValidator::new()
    .min_samples( 50 )
    .max_coefficient_variation( 0.01 )  // 1% maximum CV
    .require_warmup( true )
    .max_time_ratio( 1.2 )  // Very tight timing requirements
    .min_measurement_time( Duration::from_micros( 1 ) );
  
  // Throughput systems validator (focuses on consistency)
  let throughput_validator = BenchmarkValidator::new()
    .min_samples( 30 )
    .max_coefficient_variation( 0.05 )  // 5% maximum CV
    .require_warmup( true )
    .max_time_ratio( 2.0 )
    .min_measurement_time( Duration::from_micros( 10 ) );
  
  // Interactive systems validator (balanced)
  let interactive_validator = BenchmarkValidator::new()
    .min_samples( 20 )
    .max_coefficient_variation( 0.10 )  // 10% maximum CV
    .require_warmup( false )  // Interactive systems may not show warmup patterns
    .max_time_ratio( 3.0 )
    .min_measurement_time( Duration::from_micros( 5 ) );
  
  // Batch processing validator (more lenient)
  let batch_validator = BenchmarkValidator::new()
    .min_samples( 15 )
    .max_coefficient_variation( 0.20 )  // 20% maximum CV
    .require_warmup( false )
    .max_time_ratio( 5.0 )
    .min_measurement_time( Duration::from_micros( 50 ) );
  
  println!( "\nüìä Applying domain-specific validation..." );
  
  // Apply different validators to different algorithm categories
  let categories = vec![
    ( "encryption", &realtime_validator, "Real-time (Crypto)" ),
    ( "searching", &throughput_validator, "Throughput (Search)" ),
    ( "sorting", &interactive_validator, "Interactive (Sort)" ),
    ( "compression", &batch_validator, "Batch (Compression)" ),
  ];
  
  for ( category, validator, domain_name ) in categories
  {
    let category_results : HashMap< String, BenchmarkResult > = results.iter()
      .filter( | ( name, _ ) | name.starts_with( category ) )
      .map( | ( name, result ) | ( name.clone(), result.clone() ) )
      .collect();
    
    let validated_results = ValidatedResults::new( category_results, validator.clone() );
    
    println!( "\nüîç {} Domain ({} algorithms):", domain_name, validated_results.results.len() );
    println!( "   Reliability rate: {:.1}%", validated_results.reliability_rate() );
    
    if let Some( warnings ) = validated_results.reliability_warnings()
    {
      println!( "   Quality issues: {} warnings", warnings.len() );
      for warning in warnings.iter().take( 2 )  // Show first 2 warnings
      {
        println!( "     - {}", warning );
      }
    }
    else
    {
      println!( "   ‚úÖ All algorithms meet domain-specific criteria" );
    }
  }
  
  println!();
}

/// Advanced Pattern 2: Template Composition and Inheritance
fn pattern_template_composition()
{
  println!( "=== Pattern 2: Template Composition and Inheritance ===" );
  
  let results = create_large_scale_results();
  
  // Base template with common sections
  let _base_template = PerformanceReport::new()
    .title( "Base Performance Analysis" )
    .include_statistical_analysis( true )
    .add_custom_section( CustomSection::new(
      "Methodology",
      r#"### Test Environment

- Hardware: AMD Ryzen 9 5950X, 64GB DDR4-3600
- OS: Ubuntu 22.04 LTS with performance governor  
- Rust: 1.75.0 with full optimizations (-C target-cpu=native)
- Iterations: 20 per algorithm with warm-up cycles

### Statistical Methods

- Confidence intervals calculated using t-distribution
- Outlier detection using modified Z-score (threshold: 3.5)
- Reliability assessment based on coefficient of variation"#
    ));
  
  // Create specialized templates by composition
  
  // Security-focused template
  println!( "\nüîí Security-focused template composition..." );
  let security_template = PerformanceReport::new()
    .title( "Security Algorithm Performance Analysis" )
    .add_context( "Comprehensive analysis of cryptographic and security algorithms" )
    .include_statistical_analysis( true )
    .add_custom_section( CustomSection::new(
      "Security Considerations",
      r#"### Timing Attack Resistance

- Constant-time implementation requirements analyzed
- Side-channel vulnerability assessment included
- Performance vs security trade-offs evaluated

### Compliance Standards

- FIPS 140-2 Level 3 requirements considered
- NIST SP 800-57 key management guidelines applied
- Common Criteria EAL4+ evaluation criteria used"#
    ))
    .add_custom_section( CustomSection::new(
      "Methodology", 
      "Base methodology with security-specific considerations applied."
    ));
  
  let security_results : HashMap< String, BenchmarkResult > = results.iter()
    .filter( | ( name, _ ) | name.starts_with( "encryption" ) )
    .map( | ( name, result ) | ( name.clone(), result.clone() ) )
    .collect();
  
  let security_report = security_template.generate( &security_results ).unwrap();
  println!( "   Security template generated: {} characters", security_report.len() );
  println!( "   Contains security sections: {}", security_report.contains( "Security Considerations" ) );
  
  // Performance-optimized template
  println!( "\n‚ö° Performance-optimized template composition..." );
  let perf_template = PerformanceReport::new()
    .title( "High-Performance Algorithm Analysis" )
    .add_context( "Focus on maximum throughput and minimum latency algorithms" )
    .include_statistical_analysis( true )
    .add_custom_section( CustomSection::new(
      "Optimization Techniques",
      r#"### Applied Optimizations

- SIMD vectorization using AVX2/AVX-512 instructions
- Cache-friendly data structures and access patterns
- Branch prediction optimization and loop unrolling
- Memory prefetching and alignment strategies

### Performance Targets

- Latency: < 100Œºs for interactive operations
- Throughput: > 10GB/s for bulk processing
- CPU efficiency: > 80% cache hit rate
- Memory efficiency: < 2x theoretical minimum"#
    ))
    .add_custom_section( CustomSection::new(
      "Bottleneck Analysis",
      r#"### Identified Bottlenecks

- Memory bandwidth limitations for large datasets
- Branch misprediction penalties in irregular data
- Cache coherency overhead in multi-threaded scenarios
- System call overhead for I/O-bound operations"#
    ));
  
  let perf_results : HashMap< String, BenchmarkResult > = results.iter()
    .filter( | ( name, _ ) | name.starts_with( "sorting" ) || name.starts_with( "searching" ) )
    .map( | ( name, result ) | ( name.clone(), result.clone() ) )
    .collect();
  
  let perf_report = perf_template.generate( &perf_results ).unwrap();
  println!( "   Performance template generated: {} characters", perf_report.len() );
  println!( "   Contains optimization details: {}", perf_report.contains( "Optimization Techniques" ) );
  
  // Comparative template combining multiple analyses
  println!( "\nüìä Comparative template composition..." );
  
  // Create mega-template that combines multiple analyses
  let comprehensive_template = PerformanceReport::new()
    .title( "Comprehensive Algorithm Performance Suite" )
    .add_context( "Complete analysis across all algorithm categories with domain-specific insights" )
    .include_statistical_analysis( true )
    .add_custom_section( CustomSection::new(
      "Executive Summary",
      r#"### Key Findings

1. **Encryption algorithms**: AES-256 provides best balance of security and performance
2. **Search algorithms**: Hash lookup dominates for exact matches, binary search for ranges  
3. **Sorting algorithms**: Timsort excels for partially sorted data, quicksort for random data
4. **Compression algorithms**: LZ4 optimal for speed, Zstd for compression ratio

### Performance Rankings

| Category | Winner | Runner-up | Performance Gap |
|----------|--------|-----------|-----------------|
| Encryption | AES-256 | ChaCha20 | 15% faster |
| Search | Hash lookup | Binary search | 300% faster |
| Sorting | Timsort | Quicksort | 8% faster |
| Compression | LZ4 | Snappy | 12% faster |"#
    ))
    .add_custom_section( CustomSection::new(
      "Cross-Category Analysis",
      r#"### Algorithm Complexity Analysis

- **Linear algorithms** (O(n)): Hash operations, linear search
- **Logarithmic algorithms** (O(log n)): Binary search, tree operations  
- **Linearithmic algorithms** (O(n log n)): Optimal comparison sorts
- **Quadratic algorithms** (O(n¬≤)): Avoided in production implementations

### Memory vs CPU Trade-offs

- Hash tables: High memory usage, exceptional speed
- Tree structures: Moderate memory, consistent performance
- In-place algorithms: Minimal memory, CPU intensive
- Streaming algorithms: Constant memory, sequential processing"#
    ));
  
  let comprehensive_report = comprehensive_template.generate( &results ).unwrap();
  println!( "   Comprehensive template generated: {} characters", comprehensive_report.len() );
  println!( "   Contains executive summary: {}", comprehensive_report.contains( "Executive Summary" ) );
  println!( "   Contains cross-category analysis: {}", comprehensive_report.contains( "Cross-Category Analysis" ) );
  
  // Save all composed templates
  let temp_dir = std::env::temp_dir();
  std::fs::write( temp_dir.join( "security_analysis.md" ), &security_report ).unwrap();
  std::fs::write( temp_dir.join( "performance_analysis.md" ), &perf_report ).unwrap();
  std::fs::write( temp_dir.join( "comprehensive_analysis.md" ), &comprehensive_report ).unwrap();
  
  println!( "   üìÅ All composed templates saved to: {}", temp_dir.display() );
  
  println!();
}

/// Advanced Pattern 3: Coordinated Multi-Document Updates
fn pattern_coordinated_updates()
{
  println!( "=== Pattern 3: Coordinated Multi-Document Updates ===" );
  
  let results = create_large_scale_results();
  
  // Create multiple related documents
  let documents = vec![
    ( "README.md", vec![ ( "Performance Overview", "overview" ) ] ),
    ( "BENCHMARKS.md", vec![ ( "Detailed Results", "detailed" ), ( "Methodology", "methods" ) ] ),
    ( "OPTIMIZATION.md", vec![ ( "Optimization Guide", "guide" ), ( "Performance Tips", "tips" ) ] ),
    ( "COMPARISON.md", vec![ ( "Algorithm Comparison", "comparison" ) ] ),
  ];
  
  println!( "\nüìÑ Creating coordinated document structure..." );
  
  let temp_dir = std::env::temp_dir().join( "coordinated_docs" );
  std::fs::create_dir_all( &temp_dir ).unwrap();
  
  // Initialize documents
  for ( doc_name, sections ) in &documents
  {
    let mut content = format!( "# {}\n\n## Introduction\n\nThis document is part of the coordinated benchmark documentation suite.\n\n", 
                              doc_name.replace( ".md", "" ).replace( "_", " " ) );
    
    for ( section_name, _ ) in sections
    {
      content.push_str( &format!( "## {}\n\n*This section will be automatically updated.*\n\n", section_name ) );
    }
    
    let doc_path = temp_dir.join( doc_name );
    std::fs::write( &doc_path, &content ).unwrap();
    println!( "   Created: {}", doc_name );
  }
  
  // Generate different types of content
  println!( "\nüîÑ Generating coordinated content..." );
  
  let overview_template = PerformanceReport::new()
    .title( "Performance Overview" )
    .add_context( "High-level summary for README" )
    .include_statistical_analysis( false );  // Simplified for overview
  
  let detailed_template = PerformanceReport::new()
    .title( "Detailed Benchmark Results" )
    .add_context( "Complete analysis for technical documentation" )
    .include_statistical_analysis( true );
  
  let optimization_template = PerformanceReport::new()
    .title( "Optimization Guidelines" )
    .add_context( "Performance tuning recommendations" )
    .include_statistical_analysis( true )
    .add_custom_section( CustomSection::new(
      "Performance Recommendations",
      r#"### Algorithm Selection Guidelines

1. **For real-time applications**: Use constant-time algorithms
2. **For batch processing**: Optimize for throughput over latency
3. **For memory-constrained environments**: Choose in-place algorithms
4. **For concurrent access**: Consider lock-free data structures

### Implementation Best Practices

- Profile before optimizing - measure actual bottlenecks
- Use appropriate data structures for access patterns
- Consider cache locality in algorithm design
- Benchmark on target hardware and workloads"#
    ));
  
  // Generate all content
  let overview_content = overview_template.generate( &results ).unwrap();
  let detailed_content = detailed_template.generate( &results ).unwrap();
  let optimization_content = optimization_template.generate( &results ).unwrap();
  
  // Create comparison content
  let fastest_algorithm = results.iter()
    .min_by( | a, b | a.1.mean_time().cmp( &b.1.mean_time() ) )
    .map( | ( name, _ ) | name )
    .unwrap();
  
  let slowest_algorithm = results.iter()
    .max_by( | a, b | a.1.mean_time().cmp( &b.1.mean_time() ) )
    .map( | ( name, _ ) | name )
    .unwrap();
  
  let comparison_template = ComparisonReport::new()
    .title( "Best vs Worst Algorithm Comparison" )
    .baseline( slowest_algorithm )
    .candidate( fastest_algorithm );
  
  let comparison_content = comparison_template.generate( &results ).unwrap();
  
  // Create coordinated update plan
  println!( "\nüéØ Executing coordinated updates..." );
  
  let methodology_note = "See comprehensive methodology in detailed results above.".to_string();
  let performance_tips = "Refer to the Performance Recommendations section above for detailed guidance.".to_string();
  
  let update_plan = vec![
    ( temp_dir.join( "README.md" ), vec![ ( "Performance Overview", &overview_content ) ] ),
    ( temp_dir.join( "BENCHMARKS.md" ), vec![ 
      ( "Detailed Results", &detailed_content ),
      ( "Methodology", &methodology_note )
    ] ),
    ( temp_dir.join( "OPTIMIZATION.md" ), vec![ 
      ( "Optimization Guide", &optimization_content ),
      ( "Performance Tips", &performance_tips )
    ] ),
    ( temp_dir.join( "COMPARISON.md" ), vec![ ( "Algorithm Comparison", &comparison_content ) ] ),
  ];
  
  // Execute all updates atomically per document
  let mut successful_updates = 0;
  let mut failed_updates = 0;
  
  for ( doc_path, updates ) in update_plan
  {
    let mut chain = MarkdownUpdateChain::new( &doc_path ).unwrap();
    
    for ( section_name, content ) in updates
    {
      chain = chain.add_section( section_name, content );
    }
    
    match chain.execute()
    {
      Ok( () ) =>
      {
        successful_updates += 1;
        let file_name = doc_path.file_name().unwrap().to_string_lossy();
        println!( "   ‚úÖ {} updated successfully", file_name );
      },
      Err( e ) =>
      {
        failed_updates += 1;
        let file_name = doc_path.file_name().unwrap().to_string_lossy();
        println!( "   ‚ùå {} update failed: {}", file_name, e );
      }
    }
  }
  
  println!( "\nüìä Coordination results:" );
  println!( "   Successful updates: {}", successful_updates );
  println!( "   Failed updates: {}", failed_updates );
  println!( "   Overall success rate: {:.1}%", 
           ( successful_updates as f64 / ( successful_updates + failed_updates ) as f64 ) * 100.0 );
  
  // Create index document linking all coordinated docs
  let index_content = r#"# Benchmark Documentation Suite

This directory contains coordinated benchmark documentation automatically generated from performance analysis.

## Documents

- **[README.md](README.md)**: High-level performance overview
- **[BENCHMARKS.md](BENCHMARKS.md)**: Detailed benchmark results and methodology  
- **[OPTIMIZATION.md](OPTIMIZATION.md)**: Performance optimization guidelines
- **[COMPARISON.md](COMPARISON.md)**: Algorithm comparison analysis

## Automated Updates

All documents are automatically updated when benchmarks are run. The content is coordinated to ensure consistency across all documentation.

## Last Updated

*This suite was last updated automatically by benchkit.*
"#;
  
  std::fs::write( temp_dir.join( "INDEX.md" ), index_content ).unwrap();
  
  println!( "   üìÑ Documentation suite created at: {}", temp_dir.display() );
  
  println!();
}

/// Advanced Pattern 4: Memory-Efficient Large Scale Processing
fn pattern_memory_efficient_processing()
{
  println!( "=== Pattern 4: Memory-Efficient Large Scale Processing ===" );
  
  println!( "\nüíæ Simulating large-scale benchmark processing..." );
  
  // Simulate processing thousands of benchmark results efficiently
  let algorithm_count = 1000;  // Simulate 1000 different algorithms
  
  println!( "   Creating {} simulated algorithms...", algorithm_count );
  
  // Process results in batches to avoid memory exhaustion
  let batch_size = 100;
  let batches = ( algorithm_count + batch_size - 1 ) / batch_size;  // Ceiling division
  
  println!( "   Processing in {} batches of {} algorithms each", batches, batch_size );
  
  let mut batch_reports = Vec::new();
  let mut total_reliable = 0;
  let mut total_algorithms = 0;
  
  for batch_num in 0..batches
  {
    let start_idx = batch_num * batch_size;
    let end_idx = std::cmp::min( start_idx + batch_size, algorithm_count );
    let current_batch_size = end_idx - start_idx;
    
    println!( "   üì¶ Processing batch {}/{} ({} algorithms)...", 
             batch_num + 1, batches, current_batch_size );
    
    // Generate batch of results
    let mut batch_results = HashMap::new();
    for i in start_idx..end_idx
    {
      let times : Vec< Duration > = ( 0..15 )  // Moderate sample size for memory efficiency
        .map( | j | 
        {
          let base_time = 100 + ( i % 500 );  // Vary performance across algorithms
          let variance = j % 5;  // Small variance
          Duration::from_micros( ( base_time + variance ) as u64 )
        })
        .collect();
      
      let algorithm_name = format!( "algorithm_{:04}", i );
      batch_results.insert( algorithm_name.clone(), BenchmarkResult::new( &algorithm_name, times ) );
    }
    
    // Validate batch
    let validator = BenchmarkValidator::new()
      .min_samples( 10 )
      .require_warmup( false );  // Disable for simulated data
    
    let batch_validated = ValidatedResults::new( batch_results.clone(), validator );
    let batch_reliable = batch_validated.reliable_count();
    
    total_reliable += batch_reliable;
    total_algorithms += current_batch_size;
    
    println!( "     Batch reliability: {}/{} ({:.1}%)", 
             batch_reliable, current_batch_size, batch_validated.reliability_rate() );
    
    // Generate lightweight summary for this batch instead of full report
    let batch_summary = format!(
      "### Batch {} Summary\n\n- Algorithms: {}\n- Reliable: {} ({:.1}%)\n- Mean performance: {:.0}Œºs\n\n",
      batch_num + 1,
      current_batch_size,
      batch_reliable,
      batch_validated.reliability_rate(),
      batch_results.values()
        .map( | r | r.mean_time().as_micros() )
        .sum::< u128 >() as f64 / batch_results.len() as f64
    );
    
    batch_reports.push( batch_summary );
    
    // Explicitly drop batch data to free memory
    drop( batch_results );
    drop( batch_validated );
    
    // Simulate memory pressure monitoring
    if batch_num % 5 == 4  // Every 5 batches
    {
      println!( "     üíæ Memory checkpoint: {} batches processed", batch_num + 1 );
    }
  }
  
  // Generate consolidated summary report
  println!( "\nüìä Generating consolidated summary..." );
  
  let overall_reliability = ( total_reliable as f64 / total_algorithms as f64 ) * 100.0;
  
  let summary_template = PerformanceReport::new()
    .title( "Large-Scale Algorithm Performance Summary" )
    .add_context( format!( 
      "Memory-efficient analysis of {} algorithms processed in {} batches", 
      total_algorithms, batches 
    ))
    .include_statistical_analysis( false )  // Skip heavy analysis for summary
    .add_custom_section( CustomSection::new(
      "Processing Summary",
      format!(
        "### Scale and Efficiency\n\n- **Total algorithms analyzed**: {}\n- **Processing batches**: {}\n- **Batch size**: {} algorithms\n- **Overall reliability**: {:.1}%\n\n### Memory Management\n\n- Batch processing prevented memory exhaustion\n- Peak memory usage limited to single batch size\n- Processing completed successfully without system resource issues",
        total_algorithms, batches, batch_size, overall_reliability
      )
    ))
    .add_custom_section( CustomSection::new(
      "Batch Results",
      batch_reports.join( "" )
    ));
  
  // Use empty results since we're creating a summary-only report
  let summary_report = summary_template.generate( &HashMap::new() ).unwrap();
  
  println!( "   Summary report generated: {} characters", summary_report.len() );
  println!( "   Overall reliability across all batches: {:.1}%", overall_reliability );
  
  // Save memory-efficient summary
  let summary_file = std::env::temp_dir().join( "large_scale_summary.md" );
  std::fs::write( &summary_file, &summary_report ).unwrap();
  
  println!( "   üìÑ Large-scale summary saved to: {}", summary_file.display() );
  
  println!( "\nüí° Memory efficiency techniques demonstrated:" );
  println!( "   ‚Ä¢ Batch processing to limit memory usage" );
  println!( "   ‚Ä¢ Explicit cleanup of intermediate data" );
  println!( "   ‚Ä¢ Summary-focused reporting for scale" );
  println!( "   ‚Ä¢ Progress monitoring for long-running operations" );
  
  println!();
}

/// Advanced Pattern 5: Performance Optimization Techniques
fn pattern_performance_optimization()
{
  println!( "=== Pattern 5: Performance Optimization Techniques ===" );
  
  let results = create_large_scale_results();
  
  // Technique 1: Lazy evaluation and caching
  println!( "\n‚ö° Technique 1: Lazy evaluation and result caching..." );
  
  // Simulate expensive template generation with caching
  struct CachedTemplateGenerator
  {
    template_cache : std::cell::RefCell< HashMap< String, String > >,
  }
  
  impl CachedTemplateGenerator
  {
    fn new() -> Self
    {
      Self { template_cache : std::cell::RefCell::new( HashMap::new() ) }
    }
    
    fn generate_cached( &self, template_type : &str, results : &HashMap< String, BenchmarkResult > ) -> String
    {
      let cache_key = format!( "{}_{}", template_type, results.len() );
      
      if let Some( cached ) = self.template_cache.borrow().get( &cache_key )
      {
        println!( "     ‚úÖ Cache hit for {}", template_type );
        return cached.clone();
      }
      
      println!( "     üîÑ Generating {} (cache miss)", template_type );
      
      let report = match template_type
      {
        "performance" => PerformanceReport::new()
          .title( "Cached Performance Analysis" )
          .include_statistical_analysis( true )
          .generate( results )
          .unwrap(),
        "comparison" => 
        {
          if results.len() >= 2
          {
            let keys : Vec< &String > = results.keys().collect();
            ComparisonReport::new()
              .baseline( keys[ 0 ] )
              .candidate( keys[ 1 ] )
              .generate( results )
              .unwrap()
          }
          else
          {
            "Not enough results for comparison".to_string()
          }
        },
        _ => "Unknown template type".to_string(),
      };
      
      self.template_cache.borrow_mut().insert( cache_key, report.clone() );
      report
    }
  }
  
  let cached_generator = CachedTemplateGenerator::new();
  
  // Generate same template multiple times to demonstrate caching
  let sample_results : HashMap< String, BenchmarkResult > = results.iter()
    .take( 5 )
    .map( | ( k, v ) | ( k.clone(), v.clone() ) )
    .collect();
  
  let start_time = std::time::Instant::now();
  
  for i in 0..3
  {
    println!( "   Iteration {}: ", i + 1 );
    let _perf_report = cached_generator.generate_cached( "performance", &sample_results );
    let _comp_report = cached_generator.generate_cached( "comparison", &sample_results );
  }
  
  let total_time = start_time.elapsed();
  println!( "   Total time with caching: {:.2?}", total_time );
  
  // Technique 2: Parallel validation processing
  println!( "\nüîÄ Technique 2: Concurrent validation processing..." );
  
  // Simulate concurrent validation (simplified - actual implementation would use threads)
  let validator = BenchmarkValidator::new().require_warmup( false );
  
  let validation_start = std::time::Instant::now();
  
  // Sequential validation (baseline)
  let mut sequential_warnings = 0;
  for ( _name, result ) in &results
  {
    let warnings = validator.validate_result( result );
    sequential_warnings += warnings.len();
  }
  
  let sequential_time = validation_start.elapsed();
  
  println!( "   Sequential validation: {:.2?} ({} total warnings)", 
           sequential_time, sequential_warnings );
  
  // Simulated concurrent validation
  let _concurrent_start = std::time::Instant::now();
  
  // In a real implementation, this would use thread pools or async processing
  // For demonstration, we'll simulate the performance improvement
  let simulated_concurrent_time = sequential_time / 4;  // Assume 4x speedup
  
  println!( "   Simulated concurrent validation: {:.2?} (4x speedup)", simulated_concurrent_time );
  
  // Technique 3: Incremental updates
  println!( "\nüìù Technique 3: Incremental update optimization..." );
  
  let test_doc = std::env::temp_dir().join( "incremental_test.md" );
  
  // Create large document
  let mut large_content = String::from( "# Large Document\n\n" );
  for i in 1..=100
  {
    large_content.push_str( &format!( "## Section {}\n\nContent for section {}.\n\n", i, i ) );
  }
  
  std::fs::write( &test_doc, &large_content ).unwrap();
  
  let update_start = std::time::Instant::now();
  
  // Update multiple sections
  let report = PerformanceReport::new().generate( &sample_results ).unwrap();
  
  let incremental_chain = MarkdownUpdateChain::new( &test_doc ).unwrap()
    .add_section( "Section 1", &report )
    .add_section( "Section 50", &report )
    .add_section( "Section 100", &report );
  
  match incremental_chain.execute()
  {
    Ok( () ) =>
    {
      let update_time = update_start.elapsed();
      println!( "   Incremental updates completed: {:.2?}", update_time );
      
      let final_size = std::fs::metadata( &test_doc ).unwrap().len();
      println!( "   Final document size: {:.1}KB", final_size as f64 / 1024.0 );
    },
    Err( e ) => println!( "   ‚ùå Incremental update failed: {}", e ),
  }
  
  // Technique 4: Memory pool simulation
  println!( "\nüíæ Technique 4: Memory-efficient result processing..." );
  
  // Demonstrate processing large results without keeping everything in memory
  let processing_start = std::time::Instant::now();
  
  let mut processed_count = 0;
  let mut total_mean_time = Duration::from_nanos( 0 );
  
  // Process results one at a time instead of all at once
  for ( name, result ) in &results
  {
    // Process individual result
    let mean_time = result.mean_time();
    total_mean_time += mean_time;
    processed_count += 1;
    
    // Simulate some processing work
    if name.contains( "encryption" )
    {
      // Additional processing for security algorithms
      let _cv = result.coefficient_of_variation();
    }
    
    // Periodically report progress
    if processed_count % 5 == 0
    {
      let avg_time = total_mean_time / processed_count;
      println!( "     Processed {}: avg time {:.2?}", processed_count, avg_time );
    }
  }
  
  let processing_time = processing_start.elapsed();
  let overall_avg = total_mean_time / processed_count;
  
  println!( "   Memory-efficient processing: {:.2?}", processing_time );
  println!( "   Overall average performance: {:.2?}", overall_avg );
  println!( "   Peak memory: Single BenchmarkResult (constant)" );
  
  // Cleanup
  std::fs::remove_file( &test_doc ).unwrap();
  
  println!( "\nüéØ Performance optimization techniques demonstrated:" );
  println!( "   ‚Ä¢ Template result caching for repeated operations" );
  println!( "   ‚Ä¢ Concurrent validation processing for parallelizable work" );
  println!( "   ‚Ä¢ Incremental document updates for large files" );
  println!( "   ‚Ä¢ Stream processing for memory-efficient large-scale analysis" );
  
  println!();
}

fn main()
{
  println!( "üöÄ Advanced Usage Pattern Examples\n" );
  
  pattern_domain_specific_validation();
  pattern_template_composition();
  pattern_coordinated_updates();
  pattern_memory_efficient_processing();
  pattern_performance_optimization();
  
  println!( "üìã Advanced Usage Patterns Covered:" );
  println!( "‚úÖ Domain-specific validation: custom criteria for different use cases" );
  println!( "‚úÖ Template composition: inheritance, specialization, and reuse patterns" );
  println!( "‚úÖ Coordinated updates: multi-document atomic updates with consistency" );
  println!( "‚úÖ Memory efficiency: large-scale processing with bounded resource usage" );
  println!( "‚úÖ Performance optimization: caching, concurrency, and incremental processing" );
  println!( "\nüéØ These patterns enable sophisticated benchmarking workflows" );
  println!( "   that scale to enterprise requirements while maintaining simplicity." );
  
  println!( "\nüí° Key Takeaways for Advanced Usage:" );
  println!( "‚Ä¢ Customize validation criteria for your specific domain requirements" );
  println!( "‚Ä¢ Compose templates to create specialized reporting for different audiences" );
  println!( "‚Ä¢ Coordinate updates across multiple documents for consistency" );
  println!( "‚Ä¢ Use batch processing and caching for large-scale analysis" );
  println!( "‚Ä¢ Optimize performance through concurrency and incremental processing" );
  
  println!( "\nüìÅ Generated examples and reports saved to:" );
  println!( "   {}", std::env::temp_dir().display() );
}